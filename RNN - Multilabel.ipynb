{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label time series classification with LSTM \n",
    "\n",
    "##### Implementation of model for multi-label tims series classification as discussed in the following paper: <a href=\"https://arxiv.org/abs/1511.03677\"> Learning to diagnose with LSTM and RNNs</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods for reading and creating sequences of data for RNN/LSTM\n",
    "\n",
    "You may be need to modify these methods according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path,header = 0)\n",
    "    return data\n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "        \n",
    "def extract_segments(data, window_size = 30):\n",
    "    segments = np.empty((0,(window_size + 1)))\n",
    "    labels = np.empty((0))\n",
    "    for (start,end) in windows(data,window_size):\n",
    "        if(len(data.ix[start:end]) == (window_size + 1)):\n",
    "            signal = data.ix[start:end][\"<FEATURE COLUMN NAME>\"]\n",
    "            segments = np.vstack([segments, signal])\n",
    "            labels = np.append(labels,stats.mode(data.ix[start:end][\"<CLASS COLUMN NAME>\"])[0][0])\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "win_size = 10\n",
    "data = read_data(\"data.csv\")\n",
    "segments,labels = extract_segments(data, win_size)\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype = np.int8)\n",
    "reshaped_segments = segments.reshape([len(segments),(win_size + 1),1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split = np.random.rand(len(reshaped_segments)) < 0.80\n",
    "train_x = reshaped_segments[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = reshaped_segments[~train_test_split]\n",
    "test_y = labels[~train_test_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 10\n",
    "total_batches = (train_x.shape[0]//batch_size)\n",
    "\n",
    "n_input = 1\n",
    "n_steps = 10\n",
    "n_hidden = 64\n",
    "n_classes = 3\n",
    "\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input/Output placeholders for Tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "y_steps = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods \n",
    "\n",
    "Addition of Dropout and/or other modification to model architecture can be made in LSTM function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def LSTM(x, weight, bias):\n",
    "    cell = rnn_cell.LSTMCell(n_hidden,state_is_tuple = True)\n",
    "    multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)\n",
    "    output, state = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype = tf.float32)\n",
    "    output_flattened = tf.reshape(output, [-1, n_hidden])\n",
    "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
    "    output_all = tf.nn.sigmoid(output_logits)\n",
    "    output_reshaped = tf.reshape(output_all,[-1,n_steps,n_classes])\n",
    "    output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), n_steps - 1)  \n",
    "    #output = tf.transpose(output, [1, 0, 2])\n",
    "    #last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    #output_last = tf.nn.sigmoid(tf.matmul(last, weight) + bias)\n",
    "    return output_last, output_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = weight_variable([n_hidden,n_classes])\n",
    "bias = bias_variable([n_classes])\n",
    "y_last, y_all = LSTM(x,weight,bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary cross entropy and target replication \n",
    "\n",
    "The basic idea of target replication is to combine two losses 1) average loss of each time step prediction 2) loss of the prediction calculated at the last time step, where alpha is the combined loss function is a hyper-parameter. See the <a href=\"https://arxiv.org/abs/1511.03677\">paper</a> for more information on target replication and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_steps_cost=tf.reduce_mean(-tf.reduce_mean((y_steps * tf.log(y_all))+(1 - y_steps) * tf.log(1 - y_all),reduction_indices=1))\n",
    "all_steps_cost = -tf.reduce_mean((y_steps * tf.log(y_all))  + (1 - y_steps) * tf.log(1 - y_all))\n",
    "last_step_cost = -tf.reduce_mean((y * tf.log(y_last)) + ((1 - y) * tf.log(1 - y_last)))\n",
    "loss_function = (alpha * all_steps_cost) + ((1 - alpha) * last_step_cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(training_epochs):\n",
    "        for b in range(total_batches):    \n",
    "            offset = (b * batch_size) % (train_y.shape[0] - batch_size)\n",
    "            batch_x = train_x[offset:(offset + batch_size), :]\n",
    "            batch_y = train_y[offset:(offset + batch_size), :]\n",
    "            batch_y_steps = np.tile(batch_y,((train_x.shape[1]),1))\n",
    "            _, c = session.run([optimizer, loss_function],feed_dict={x: batch_x, y : batch_y, y_steps: batch_y_steps})   \n",
    "        pred_y = session.run(y_last,feed_dict={x:test_x})\n",
    "        print(\"ROC AUC Score: \",roc_auc_score(test_y,pred_y))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
